{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from scipy.linalg import eigh\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "path = 'F:\\\\3-1\\\\RESIZED_DATASET'\n",
    "myList = os.listdir(path)\n",
    "print(len(myList))\n",
    "noOfClasses = len(myList)\n",
    "images=[]\n",
    "classNo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,noOfClasses):\n",
    "    myPicList = os.listdir(path+\"/\"+str(x))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path+\"/\"+str(x)+\"/\"+y)\n",
    "        curImg = cv2.resize(curImg,(128,128))\n",
    "        images.append(curImg)\n",
    "        classNo.append(x)\n",
    "    #print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11061\n",
      "11061\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(classNo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11061, 128, 128, 3)\n",
      "(11061,)\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    "print(images.shape)\n",
    "print(classNo.shape)\n",
    "testRatio=0.2\n",
    "validationRatio=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(images,classNo,test_size=testRatio)\n",
    "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size=validationRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7078, 128, 128, 3)\n",
      "(1770, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204, 182, 182, 178, 164, 193, 187, 168, 184, 191, 202, 192, 169, 189, 167, 184, 186, 196, 189, 189, 198, 186, 193, 192, 176, 188, 182, 197, 176, 177, 185, 183, 198, 199, 180, 196, 184, 192]\n"
     ]
    }
   ],
   "source": [
    "numOfSamples= []\n",
    "for x in range(0,noOfClasses):\n",
    "    #print(len(np.where(y_train==x)[0]))\n",
    "    numOfSamples.append(len(np.where(y_train==x)[0]))\n",
    "print(numOfSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(list(map(preProcessing,X_train)))\n",
    "X_test = np.array(list(map(preProcessing,X_test)))\n",
    "X_validation = np.array(list(map(preProcessing,X_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7078, 128, 128)\n",
      "(7078, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "X_validation = X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10)\n",
    "dataGen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7078, 38)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train,noOfClasses)\n",
    "y_test = to_categorical(y_test,noOfClasses)\n",
    "y_validation = to_categorical(y_validation,noOfClasses)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDimensions=(128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 60)      1560      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 120, 60)      90060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 60, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 58, 30)        16230     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 30)        8130      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 30)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 30)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 23520)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               11760500  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 38)                19038     \n",
      "=================================================================\n",
      "Total params: 11,895,518\n",
      "Trainable params: 11,895,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def myModel():\n",
    "    noOfFilters = 60\n",
    "    sizeOfFilter1 = (5,5)\n",
    "    sizeOfFilter2 = (3, 3)\n",
    "    sizeOfPool = (2,2)\n",
    "    noOfNodes= 500\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add((Conv2D(noOfFilters,sizeOfFilter1,input_shape=(imageDimensions[0],\n",
    "                      imageDimensions[1],1),activation='relu')))\n",
    "    model.add((Conv2D(noOfFilters, sizeOfFilter1, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add((Conv2D(noOfFilters//2, sizeOfFilter2, activation='relu')))\n",
    "    model.add((Conv2D(noOfFilters//2, sizeOfFilter2, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add(Dropout(0.5))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(noOfNodes,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(noOfClasses, activation='softmax'))\n",
    " \n",
    "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "model = myModel()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSizeVal = 50\n",
    "epochsVal = 10\n",
    "stepsPerEpochVal = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7078 samples, validate on 1770 samples\n",
      "Epoch 1/10\n",
      "7078/7078 [==============================] - 225s 32ms/step - loss: 3.4194 - accuracy: 0.0911 - val_loss: 2.8346 - val_accuracy: 0.2446\n",
      "Epoch 2/10\n",
      "7078/7078 [==============================] - 182s 26ms/step - loss: 2.6137 - accuracy: 0.2793 - val_loss: 2.1698 - val_accuracy: 0.3949\n",
      "Epoch 3/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 1.9111 - accuracy: 0.4459 - val_loss: 1.8571 - val_accuracy: 0.4842\n",
      "Epoch 4/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 1.3783 - accuracy: 0.5886 - val_loss: 1.7580 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "7078/7078 [==============================] - 182s 26ms/step - loss: 1.0071 - accuracy: 0.6919 - val_loss: 1.7808 - val_accuracy: 0.5328\n",
      "Epoch 6/10\n",
      "7078/7078 [==============================] - 181s 26ms/step - loss: 0.7699 - accuracy: 0.7578 - val_loss: 1.7659 - val_accuracy: 0.5294\n",
      "Epoch 7/10\n",
      "7078/7078 [==============================] - 182s 26ms/step - loss: 0.6007 - accuracy: 0.8136 - val_loss: 1.8789 - val_accuracy: 0.5463\n",
      "Epoch 8/10\n",
      "7078/7078 [==============================] - 577s 82ms/step - loss: 0.4790 - accuracy: 0.8460 - val_loss: 1.9062 - val_accuracy: 0.5463\n",
      "Epoch 9/10\n",
      "7078/7078 [==============================] - 1256s 177ms/step - loss: 0.4374 - accuracy: 0.8572 - val_loss: 1.9808 - val_accuracy: 0.5458\n",
      "Epoch 10/10\n",
      "7078/7078 [==============================] - 1214s 172ms/step - loss: 0.3715 - accuracy: 0.8760 - val_loss: 1.9658 - val_accuracy: 0.5520\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_validation,y_validation), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8990095019394382, 0.5666515827178955]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test,verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "while True:\n",
    "    success,imgOriginal = cap.read()\n",
    "    img = np.asarray(imgOriginal)\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    img = preProcessing(img)\n",
    "    cv2.imshow(\"Processed Image\",img)\n",
    "    img=img.reshape(1,128,128,1)\n",
    "    classIndex = int(model.predict_classes(img))\n",
    "    #print(classIndex)\n",
    "    predictions = model.predict(img)\n",
    "    probVal = np.amax(predictions)\n",
    "    cv2.putText(imgOriginal,str(classIndex)+\" \"+str(probVal),(50,50),\n",
    "               cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "    cv2.imshow(\"Original Image\",imgOriginal)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath='F:\\\\3-1\\\\RESIZED_TESTING_DATA\\\\8\\\\20180714_232511.jpg'\n",
    "image = cv2.imread(newpath)\n",
    "cv2.imshow(\"Processed Image\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpath='F:\\\\3-1\\\\RESIZED_TESTING_DATA\\\\20\\\\20180716_000301.jpg'\n",
    "while True:\n",
    "    #success,imgOriginal = cap.read()\n",
    "    imgOriginal = cv2.imread(newpath)\n",
    "    img = cv2.imread(newpath)\n",
    "    #img = np.asarray(imgOriginal)\n",
    "    img = cv2.resize(img,(128,128))\n",
    "    img = preProcessing(img)\n",
    "    cv2.imshow(\"Processed Image\",img)\n",
    "    img=img.reshape(1,128,128,1)\n",
    "    classIndex = int(model.predict_classes(img))\n",
    "    #print(classIndex)\n",
    "    predictions = model.predict(img)\n",
    "    probVal = np.amax(predictions)\n",
    "    cv2.putText(imgOriginal,str(classIndex)+\" \"+str(probVal),(50,50),\n",
    "               cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "    cv2.imshow(\"Original Image\",imgOriginal)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
